opcode         name       target                             args          kwargs
-------------  ---------  ---------------------------------  ------------  --------
placeholder    l_b_       L_b_                               ()            {}
call_function  getitem    <built-in function getitem>        (l_b_, 0)     {}
call_function  getitem_1  <built-in function getitem>        (getitem, 0)  {}
call_function  silu       <function silu at 0x7f9c4beff920>  (getitem_1,)  {}
output         output     output                             ((silu,),)    {}
+++++++++++++++++++++++
{'graph': <torch.fx.graph.Graph object at 0x7f9c49654790>, 'name': 'arg0_1', 'op': 'placeholder', 'target': 'arg0_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {select: None}, 'type': None, '_prev': , '_next': select, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(1024, 1024)), 'tensor_meta': TensorMetadata(shape=torch.Size([1024, 1024]), dtype=torch.float32, requires_grad=False, stride=(1024, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f9c49654790>, 'name': 'select', 'op': 'call_function', 'target': <OpOverload(op='aten.select', overload='int')>, '_input_nodes': {arg0_1: None}, '_args': (arg0_1, 0, 0), '_kwargs': {}, 'users': {select_1: None}, 'type': None, '_prev': arg0_1, '_next': select_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/buddy-mlir/examples/BuddyGraph/import-dynamo-break.py", line 15, in forward\n    if not torch.nn.functional.silu(b[0][0]):\n', 'source_fn': ('getitem', <built-in function getitem>), 'original_aten': <OpOverload(op='aten.select', overload='int')>, 'from_node': [('getitem', <built-in function getitem>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1024,)), 'tensor_meta': TensorMetadata(shape=torch.Size([1024]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f9c49654790>, 'name': 'select_1', 'op': 'call_function', 'target': <OpOverload(op='aten.select', overload='int')>, '_input_nodes': {select: None}, '_args': (select, 0, 0), '_kwargs': {}, 'users': {silu: None}, 'type': None, '_prev': select, '_next': silu, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/buddy-mlir/examples/BuddyGraph/import-dynamo-break.py", line 15, in forward\n    if not torch.nn.functional.silu(b[0][0]):\n', 'source_fn': ('getitem_1', <built-in function getitem>), 'original_aten': <OpOverload(op='aten.select', overload='int')>, 'from_node': [('getitem_1', <built-in function getitem>)], 'seq_nr': -1, 'val': FakeTensor(..., size=()), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.float32, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f9c49654790>, 'name': 'silu', 'op': 'call_function', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {select_1: None}, '_args': (select_1,), '_kwargs': {}, 'users': {output: None}, 'type': None, '_prev': select_1, '_next': output, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/buddy-mlir/examples/BuddyGraph/import-dynamo-break.py", line 15, in forward\n    if not torch.nn.functional.silu(b[0][0]):\n', 'source_fn': ('silu', <function silu at 0x7f9c4beff920>), 'original_aten': <OpOverload(op='aten.silu', overload='default')>, 'from_node': [('silu', <function silu at 0x7f9c4beff920>)], 'seq_nr': -1, 'val': FakeTensor(..., size=()), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.float32, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f9c49654790>, 'name': 'output', 'op': 'output', 'target': 'output', '_input_nodes': {silu: None}, '_args': ((silu,),), '_kwargs': {}, 'users': {}, 'type': None, '_prev': silu, '_next': , '_erased': False, '_repr_fn': None, 'meta': {}}
------------------
opcode         name    target                                                  args          kwargs
-------------  ------  ------------------------------------------------------  ------------  --------
placeholder    l_b_    L_b_                                                    ()            {}
placeholder    l_c_    L_c_                                                    ()            {}
call_function  add     <built-in method add of type object at 0x7f9cc57b0aa0>  (l_b_, l_c_)  {}
output         output  output                                                  ((add,),)     {}
+++++++++++++++++++++++
{'graph': <torch.fx.graph.Graph object at 0x7f9c3f0e7f50>, 'name': 'arg0_1', 'op': 'placeholder', 'target': 'arg0_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {add: None}, 'type': None, '_prev': , '_next': arg1_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(1024, 1024)), 'tensor_meta': TensorMetadata(shape=torch.Size([1024, 1024]), dtype=torch.float32, requires_grad=False, stride=(1024, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f9c3f0e7f50>, 'name': 'arg1_1', 'op': 'placeholder', 'target': 'arg1_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {add: None}, 'type': None, '_prev': arg0_1, '_next': add, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(1024, 1024)), 'tensor_meta': TensorMetadata(shape=torch.Size([1024, 1024]), dtype=torch.float32, requires_grad=False, stride=(1024, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f9c3f0e7f50>, 'name': 'add', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {arg0_1: None, arg1_1: None}, '_args': (arg0_1, arg1_1), '_kwargs': {}, 'users': {output: None}, 'type': None, '_prev': arg1_1, '_next': output, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/buddy-mlir/examples/BuddyGraph/import-dynamo-break.py", line 18, in <resume in forward>\n    return torch.add(b, c)\n', 'source_fn': ('add', <built-in method add of type object at 0x7f9cc57b0aa0>), 'original_aten': <OpOverload(op='aten.add', overload='Tensor')>, 'from_node': [('add', <built-in method add of type object at 0x7f9cc57b0aa0>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1024, 1024)), 'tensor_meta': TensorMetadata(shape=torch.Size([1024, 1024]), dtype=torch.float32, requires_grad=False, stride=(1024, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f9c3f0e7f50>, 'name': 'output', 'op': 'output', 'target': 'output', '_input_nodes': {add: None}, '_args': ((add,),), '_kwargs': {}, 'users': {}, 'type': None, '_prev': add, '_next': , '_erased': False, '_repr_fn': None, 'meta': {}}
------------------
None
